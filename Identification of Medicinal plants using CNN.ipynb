{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "## Part 1 - Data Preprocessing\n",
        "### Preprocessing the Training set\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "    'Dataset/train',\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'  # Use 'categorical' for multiple classes\n",
        ")\n",
        "\n",
        "### Preprocessing the Test set\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    'Dataset/test',\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,  # Match the training set batch size for consistency\n",
        "    class_mode='categorical'  # Use 'categorical' for multiple classes\n",
        ")\n",
        "\n",
        "## Part 2 - Building the CNN\n",
        "### Initialising the CNN\n",
        "cnn = tf.keras.models.Sequential()\n",
        "\n",
        "### Step 1 â€“ Convolution\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=50, kernel_size=3, activation='relu', input_shape=[128, 128, 3]))\n",
        "\n",
        "### Step 2 - Pooling\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "\n",
        "### Adding a second convolutional layer\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=60, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "\n",
        "### Step 3 - Flattening\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "\n",
        "### Step 4 - Full Connection\n",
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "# cnn.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
        "# cnn.add(tf.keras.layers.Dense(units=90, activation='relu'))\n",
        "\n",
        "### Step 5 - Output Layer\n",
        "num_plant_classes = 4  # Change this to the number of plant classes\n",
        "cnn.add(tf.keras.layers.Dense(units=num_plant_classes, activation='softmax'))\n",
        "\n",
        "## Part 3 - Training the CNN\n",
        "### Compiling the CNN\n",
        "learning_rate = 0.001\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "cnn.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "### Training the CNN on the Training set and evaluating it on the Test set\n",
        "cnn.fit(x=training_set, validation_data=test_set, epochs=25)\n",
        "\n",
        "## Part 4 - Making a single prediction\n",
        "# Loading an image you want to classify\n",
        "test_image = image.load_img('Dataset/single_prediction/plant_alo.jpg', target_size=(128, 128))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis=0)\n",
        "test_image = test_image / 255.0\n",
        "\n",
        "result = cnn.predict(test_image)\n",
        "plant_classes = training_set.class_indices\n",
        "predicted_class = list(plant_classes.keys())[np.argmax(result)]\n",
        "print(\"The predicted class is:\", predicted_class)\n",
        "\n",
        "## Saving and Loading the Model\n",
        "### Saving the model\n",
        "cnn.save('plant_model.h5')\n",
        "\n",
        "### Loading the model\n",
        "loaded_model = load_model('plant_model.h5')\n"
      ],
      "metadata": {
        "id": "q1R9CZu-r8p6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}